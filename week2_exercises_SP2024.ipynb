{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent and backpropagation\n",
    "\n",
    "- Part 2.1: With the same neural network from last week, understand how stochastic gradient descent is implemented.\n",
    "- Part 2.2: Do pen and paper calculations of backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T10:13:40.271320Z",
     "start_time": "2020-01-20T10:13:40.266929Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pylab as plt\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1: Understanding SGD\n",
    "\n",
    "Let's reuse Michael Nielsen's neural network from last session. Some new question are inserted in the comments (they start with \"Q: \"). Michael uses [list comprehensions](https://www.w3schools.com/python/python_lists_comprehension.asp) a lot, so make sure to learn that syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T14:51:15.694576Z",
     "start_time": "2020-01-21T14:51:15.661650Z"
    }
   },
   "outputs": [],
   "source": [
    "# Miscellaneous functions\n",
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "def step(z, threshold=0.5):\n",
    "    if z > threshold:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# Feed forward neural network class\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"The list ``sizes`` contains the number of neurons in the\n",
    "        respective layers of the network.  For example, if the list\n",
    "        was [2, 3, 1] then it would be a three-layer network, with the\n",
    "        first layer containing 2 neurons, the second layer 3 neurons,\n",
    "        and the third layer 1 neuron.  The biases and weights for the\n",
    "        network are initialized randomly, using a Gaussian\n",
    "        distribution with mean 0, and variance 1.  Note that the first\n",
    "        layer is assumed to be an input layer, and by convention we\n",
    "        won't set any biases for those neurons, since biases are only\n",
    "        ever used in computing the outputs from later layers.\"\"\"\n",
    "        \n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
    "        \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a) + b)\n",
    "        return a\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, lr, test_data=None, silent=False):\n",
    "        \"\"\"Train the neural network using mini-batch stochastic\n",
    "        gradient descent.  The ``training_data`` is a list of tuples\n",
    "        ``(x, y)`` representing the training inputs and the desired\n",
    "        outputs.  The other non-optional parameters are\n",
    "        self-explanatory.  If ``test_data`` is provided then the\n",
    "        network will be evaluated against the test data after each\n",
    "        epoch, and partial progress printed out.  This is useful for\n",
    "        tracking progress, but slows things down substantially.\"\"\"\n",
    "        \n",
    "        n = len(training_data)\n",
    "        if test_data:\n",
    "            n_test = len(test_data)\n",
    "        \n",
    "        for j in range(epochs):\n",
    "            \n",
    "            # Q1: What happens here? Explain the contents of `mini_batches`.\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)\n",
    "            ]\n",
    "            \n",
    "            # Q2: And what does this step do?\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, lr)\n",
    "            \n",
    "            if not silent:\n",
    "                if test_data:\n",
    "                    print(\"Epoch {0}: {1} / {2}\".format(j, self.evaluate(test_data), n_test))\n",
    "                else:\n",
    "                    print(\"Epoch {0} complete\".format(j))\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, lr):\n",
    "        \"\"\"Update the network's weights and biases by applying\n",
    "        gradient descent using backpropagation to a single mini batch.\n",
    "        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``lr``\n",
    "        is the learning rate.\"\"\"\n",
    "        \n",
    "        # These two vectors correspond to -∇C(W) (and -∇C(b))\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        # Q3: How does this code work to update `nabla_b` and `nabla_w`\n",
    "        for x, y in mini_batch:\n",
    "            nabla_b_i, nabla_w_i = self.backprop(x, y)\n",
    "            nabla_b = [nb+nb_i for nb, nb_i in zip(nabla_b, nabla_b_i)]\n",
    "            nabla_w = [nw+nw_i for nw, nw_i in zip(nabla_w, nabla_w_i)]\n",
    "            \n",
    "        # Q4: Now we have our gradient vectors, `nabla_b` and `nabla_w`. Explain how we use them\n",
    "        # to update the weights and biases\n",
    "        self.weights = [\n",
    "            w - lr * nw / len(mini_batch)\n",
    "            for w, nw in zip(self.weights, nabla_w)\n",
    "        ]\n",
    "        self.biases = [\n",
    "            b - lr * nb / len(mini_batch)\n",
    "            for b, nb in zip(self.biases, nabla_b)\n",
    "        ]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
    "        gradient for the cost function C_x.  ``nabla_b`` and\n",
    "        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
    "        to ``self.biases`` and ``self.weights``.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        # In backprop, we first do a feed forward step. We store all the\n",
    "        # intermediate values that get computed. This is because, when we\n",
    "        # compute the gradient on a weight, we ask how changing it a little\n",
    "        # might influence the value that gets computed with it. Hence we need\n",
    "        # to store these values.\n",
    "        \n",
    "        # Feedforward # \n",
    "        # ----------- #\n",
    "        \n",
    "        activation = x\n",
    "        activations = [x] # list to store all the activations, layer by layer\n",
    "        zs = [] # list to store all the z vectors, layer by layer\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation) + b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        \n",
    "        \n",
    "        # Backward pass # \n",
    "        # ------------- #\n",
    "        \n",
    "        # Q5: What does the variable `delta` store here? Why is the last bias\n",
    "        # gradient exactly `delta`?\n",
    "        delta = self.cost_derivative(activations[-1], y) * sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        \n",
    "        # Q6: Seems like we are multiplying each of the outputs from the previous\n",
    "        # layer, with the delta. Can you explain why we do this? \n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        \n",
    "        # Note that the variable l in the loop below is used a little\n",
    "        # differently to the notation in Chapter 2 of the book. Here,\n",
    "        # l = 1 means the last layer of neurons, l = 2 is the\n",
    "        # second-last layer, and so on. It's a renumbering of the\n",
    "        # scheme in the book, used here to take advantage of the fact\n",
    "        # that Python can use negative indices in lists.\n",
    "        \n",
    "        # Q7: What does this loop do?\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "            \n",
    "        return nabla_b, nabla_w\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        \"\"\"Return the number of test inputs for which the neural\n",
    "        network outputs the correct result. Note that the neural\n",
    "        network's output is assumed to be the index of whichever\n",
    "        neuron in the final layer has the highest activation.\"\"\"\n",
    "        if self.sizes[-1] == 1:\n",
    "            test_results = [\n",
    "                (step(self.feedforward(x)), y)\n",
    "                for x, y in test_data\n",
    "            ]\n",
    "        else:\n",
    "            test_results = [\n",
    "                (np.argmax(self.feedforward(x)), y)\n",
    "                for x, y in test_data\n",
    "            ]\n",
    "        return sum(int(y_pred == y) for (y_pred, y) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        \"\"\"Return the vector of partial derivatives dC_x/da\n",
    "        for the output activations.\"\"\"\n",
    "        return output_activations - y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 2.1.1** Draw a overview illustrating which method depend on which method in the `Network` class. Below, give a short explanation as to what each method does.\n",
    ">\n",
    "> *Hint*: You can draw by hand take a picture and put it into the notebook, work your paint skills, make ascii art or whatever your inner creative finds easiest. Just as long as one can somehow read the relations in your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Cost_Derivative\n",
    "cost_derivative method returns the vector of partial derivatives, in order to determine the new output activations. Essentially returning the output activations - y. \n",
    "# 2) Backprop\n",
    "the backprop method utelizes the cost_derivative method and returns a tuple of two numpy arrays, similar to the biases and weights necessary to compute the backpropogation. It does a forward pass to store all activations followed by a backwards pass to determine the new values of biases and weights. This ultimately returns the updated weight and biase values that reduce the loss for the network.\n",
    "# 3) Feedforward\n",
    "the feedforward method performs a forward pass on the network and returns the prediction of the network for a certain value input.\n",
    "# 4) Update mini batch\n",
    "the update_mini_batch method updates the network's weights and biases based on the gradients computed from the mini-batch.\n",
    "# 5 Evaluate\n",
    "Evalute returns the number of correctly predicted examples in the data, essentially assessing the networks performance on a given dataset. \n",
    "# 6  SGD\n",
    "SGD trains the network on the training data using stochastic gradient descent to minimize the loss. \n",
    "# 7) Sigmoid\n",
    "Sigmoid and Sigmoid prime implement the sigmoid activation function and its derivative."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![netilusstration](https://github.com/daisy-abbott/NeuralNets/assets/112681549/3150aff3-9491-407b-a9e3-9a0450112853)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          \n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 2.1.2** Answer questions Q1-4 in the code. Write / code down the answer to each one of them in cells below.\n",
    ">\n",
    "> *Hint*: You need to closely follow the code. You can verify that your idea of what a variable contains is correct, if you print it. Simply create an instance of the network and you will be able to access the variables of that instance to see what they look like. Example:\n",
    ">\n",
    ">     net = Network([2, 3, 1])\n",
    ">     net.biases  # this gets you the biases property of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer to Q1\n",
    "\n",
    "Inside the first for loop (for j), the training data is randomly shuffled as to not bias the network to learn in a particular way. Next, mini_batches is created from the training data by selecting slices from the training data with a size of mini_batch_size. Then the network loops from 0 to n iterations (the entirety of the training data) in steps of mini_batch_size. Each mini batch is a subset of the training data that will be used for updating the weights of the network. \n",
    "\n",
    "# Answer to Q2\n",
    "This section of code iterates over each mini batch generated by the previous code. For each mini batch, it calls the update_mini_batch method of the neural network, passing in the mini-batch and the learning rate. The update_mini_batch method then performs the backpropagation and weight/bias updates based on the gradients computed from the mini-batch.\n",
    "\n",
    "\n",
    "# Answer to Q3\n",
    "Here, we iterate through each training example (x, y) in the mini batch. Then we backpropagate through the network storing the adjustments that should be made to these weights/biases in nabla_b and nabla_w. \n",
    "\n",
    "\n",
    "# Answer to Q4: \n",
    "Next, we update the weights and biases by subtracting the gradients calculated in the backpropagation from the current weight. This process minimizes the loss and makes sure that the network is trained to make more accurate predictions. \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.1: Backpropagation\n",
    "\n",
    "**Your understanding** of neural networks should now be something along the lines of: (1) a datapoint propagates forward through the network, then (2) a cost (how bad the prediction is) is evaluated and its gradient wrt. each weight is computed, and finally (3) the weights are updated according to how much they influence the cost.\n",
    "\n",
    "However, something important is missing from our understanding at this point. Remember, that *gradient descent* – the algorithm for minimizing the cost function, which we can think of as ball rolling downhill – needs to known which direction is downhill on the cost function. The gradient tells us this. **So how do we compute the cost function's gradient?** Enter: *backpropagation*. Backpropagation is an algorithm which computes the gradient of the cost function wrt. each weight in the network, from end to start, by iteratively applying *the chain rule*. It is called *back*-propagation because it computes gradients from front to back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pen and paper calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, do some pen and paper calculations to hand-compute gradients in a real neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ![img](https://raw.githubusercontent.com/abjer/tsds/master/material_exercises/week_3/2_3_1_net.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 2.2.1**: The network above has a defined input and weights. If the true label for the datapoint `[4, 2]` is 1, what is the cost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0812"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0812"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 2.2.2**: Knowing about backpropagation, we actually have everything we need to compute the gradients of the weights by hand. So go ahead and do that. Report your answer either as a diagram that includes the gradients (you can draw on my figure somehow and insert the resulting image), or just by writing what the gradient of each weight is.\n",
    ">\n",
    "> *Hint*: When computing gradients with backprop, it can be helpful to think of the network as a [computational graph](https://github.com/abjer/tsds/blob/master/material_exercises/week_3/2_3_1_net_compgraph.png?raw=true).\n",
    ">\n",
    "> *Hint*: Some of the gradients will become *very* small, known as the vanishing gradient problem. If they get smaller than 1e-4 you can just set them to zero.*\n",
    ">\n",
    "> *Note*: If you show me which equations you used and what your process is, I can give better feedback in case there are mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 2.2.3:** Provide answers to the code questions Q5-7.\n",
    ">\n",
    ">*Note:* `Q7` relies on having a solid grasp of the backpropagation equations (BP1-4) of Micheal Nielsens book. These cast what we learned today in vector notation, using matrix multiplication to compute the gradients of *vectors and matrices of weights*. You are not required to know these equations - the important thing is that you grasp the key ideas of backpropagation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Q5 \n",
    "The variable delta stores the error in the output layer of the network. The last bias gradient is updated \n",
    "to equal delta because the derivative of the cost function with respect to the bias in the final layer is \n",
    "the same as the error. This is because of the chain rule. \n",
    "\n",
    "# Q6 \n",
    "Multiplying the outputs from the previous layer with delta helps figure out how much each connection contributed to the networks' error. The dot product then combines delta with the output to make adjustments to the connections and reduce overall prediction errors during training.\n",
    "\n",
    "# Q7 \n",
    "The loop iterates through the network backwards, exlcuding the input layer and stopping before reaching the output layer. Each iteration, it computes the error (or delta) for the current layer, updates the bias (nabla_b), and computes the weight gradient (nable_w). It essentially does the backpropagation, adjusting errors backward through the layers to compute gradients for weight and bias updates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
